import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets
from torch.cuda.amp import GradScaler, autocast
import timm
from timm.data import create_transform
from timm.scheduler import CosineLRScheduler
import os
import time
import math
from tqdm import tqdm
from timm.data import resolve_data_config # å¿…é¡»å¼•å…¥è¿™ä¸ª

# ==========================================
# 1. æ ¸å¿ƒæ•°å­¦ç»„ä»¶
# ==========================================
def get_hadamard_matrix(n, device='cuda'):
    if n == 1: return torch.tensor([[1.]], device=device)
    h = get_hadamard_matrix(n // 2, device)
    return torch.cat([torch.cat([h, h], dim=1), torch.cat([h, -h], dim=1)], dim=0)

def generate_golay_sequence(length):
    if length <= 0: return torch.tensor([])
    n = 2 ** math.ceil(math.log2(length))
    def _recursive(k):
        if k == 1: return torch.tensor([1.]), torch.tensor([1.])
        a, b = _recursive(k // 2)
        return torch.cat([a, b]), torch.cat([a, -b])
    full_seq, _ = _recursive(n)
    return full_seq[:length]

class BlockHadamardTransform(nn.Module):
    def __init__(self, dim, block_size=128):
        super().__init__()
        if dim % block_size != 0:
            print(f"âš ï¸ ç»´åº¦ {dim} æ— æ³•è¢« {block_size} æ•´é™¤ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸º 128")
            block_size = 128
        self.block_size = block_size
        H = get_hadamard_matrix(self.block_size, device='cpu') / math.sqrt(self.block_size)
        self.register_buffer('hadamard_matrix', H)

    def forward(self, x):
        original_shape = x.shape
        x_reshaped = x.view(*original_shape[:-1], -1, self.block_size)
        x_trans = torch.matmul(x_reshaped, self.hadamard_matrix)
        return x_trans.view(original_shape)

# ==========================================
# 2. ä¼˜åŒ–åŽçš„ Layer (æƒé‡å·²æ˜¯å˜æ¢åŸŸ)
# ==========================================
class GolayFWHTLinear(nn.Linear):
    def __init__(self, in_features, out_features, bias=True, block_size=128):
        super().__init__(in_features, out_features, bias)
        
        # åªéœ€è¦å˜æ¢ç®—å­å¤„ç†è¾“å…¥
        self.transform = BlockHadamardTransform(in_features, block_size)
        
        # Golay åºåˆ— (è¾“å…¥è¿˜éœ€è¦å®ƒ)
        self.register_buffer('golay', generate_golay_sequence(in_features))
        
    def forward(self, x):
        # 1. ä»…å¯¹è¾“å…¥è¿›è¡Œå˜æ¢
        # X_new = FWHT(X * G)
        x_mod = x * self.golay
        x_trans = self.transform(x_mod)
        
        # 2. çº¿æ€§è®¡ç®—
        # è¿™é‡Œçš„ self.weight å·²ç»æ˜¯å˜æ¢åŽçš„æƒé‡ W_trans äº†ï¼
        # å…¬å¼: Y = X_trans @ W_trans.T + b
        # ä¸éœ€è¦å†å¯¹ weight åš FWHT
        return F.linear(x_trans, self.weight, self.bias)

# ==========================================
# 3. ä¼˜åŒ–åŽçš„æ‰‹æœ¯å‡½æ•° (é¢„è®¡ç®—æƒé‡)
# ==========================================
def replace_linear_with_golay(model, block_size=128):
    print(f"ðŸ”ª å¼€å§‹æ‰‹æœ¯: é¢„è®¡ç®—æƒé‡å¹¶æ›¿æ¢ Layer (BlockSize={block_size})...")
    
    # 1. å¼ºåˆ¶å°†æ¨¡åž‹ç§»åˆ° CPU è¿›è¡Œæ‰‹æœ¯ (é¿å…æ˜¾å­˜ OOM å’Œè®¾å¤‡å†²çª)
    # è¿™æ˜¯æœ€ç¨³å¦¥çš„æ–¹æ³•ï¼Œæ‰‹æœ¯å®Œå†ç§»å›ž GPU
    model.cpu()
    
    count = 0
    embed_dim = model.embed_dim
    
    # åˆå§‹åŒ–å˜æ¢ç®—å­ (åœ¨ CPU)
    transformer = BlockHadamardTransform(embed_dim, block_size)
    golay = generate_golay_sequence(embed_dim)
    
    def convert_weight(old_weight):
        """å°†åŽŸå§‹æƒé‡è½¬æ¢ä¸ºå˜æ¢åŸŸæƒé‡"""
        # ç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½åœ¨ CPU
        # old_weight å·²ç»æ˜¯ CPU äº† (å› ä¸º model.cpu())
        # golay å’Œ transformer ä¹Ÿæ˜¯ CPU
        with torch.no_grad():
            w_mod = old_weight * golay
            w_trans = transformer(w_mod)
        return w_trans

    for i, block in enumerate(model.blocks):
        # --- 1. Replace QKV ---
        if hasattr(block.attn, 'qkv'):
            old = block.attn.qkv
            new_layer = GolayFWHTLinear(old.in_features, old.out_features, old.bias is not None, block_size)
            
            # è½¬æ¢æƒé‡
            new_layer.weight.data = convert_weight(old.weight.data)
            
            if old.bias is not None: 
                new_layer.bias.data = old.bias.data.clone()
            block.attn.qkv = new_layer
            count += 1
            
        # --- 2. Replace FC1 ---
        if hasattr(block.mlp, 'fc1'):
            old = block.mlp.fc1
            new_layer = GolayFWHTLinear(old.in_features, old.out_features, old.bias is not None, block_size)
            
            # è½¬æ¢æƒé‡
            new_layer.weight.data = convert_weight(old.weight.data)
            
            if old.bias is not None: 
                new_layer.bias.data = old.bias.data.clone()
            block.mlp.fc1 = new_layer
            count += 1

    print(f"âœ… æ‰‹æœ¯å®Œæˆï¼Œå…±æ›¿æ¢ {count} å±‚ã€‚æ¨¡åž‹ç›®å‰åœ¨ CPUã€‚")
    return model
# ==========================================
# 2. ç‹¬ç«‹éªŒè¯å‡½æ•°
# ==========================================
def validate_model(model, loader, device, description="Validation"):
    """ç‹¬ç«‹çš„éªŒè¯å¾ªçŽ¯"""
    model.eval()
    correct = 0
    total = 0
    print(f"ðŸ” å¼€å§‹éªŒè¯: {description} ...")
    
    with torch.no_grad():
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        for images, labels in tqdm(loader, desc=description, leave=True):
            images, labels = images.to(device), labels.to(device)
            # ä¿æŒå’Œè®­ç»ƒä¸€è‡´çš„æ··åˆç²¾åº¦
            with autocast():
                outputs = model(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
    acc = 100. * correct / total
    print(f"ðŸ“‹ {description} ç»“æžœ: Accuracy = {acc:.2f}%")
    return acc

# ================= é…ç½®åŒºåŸŸ =================
CONFIG = {
    'data_dir': '/content/imagenet', 
    'model_name': 'vit_small_patch16_224.augreg_in21k',
    'num_classes': 1000,
    'pretrained': True,
    'batch_size': 32,
    'epochs': 30,
    'lr': 1e-4, 
    'weight_decay': 0.05,
    'num_workers': 4,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
}

def main():
    print(f"ðŸš€ ä»»åŠ¡ç±»åž‹: å¾®è°ƒ (Golay + FWHT)")

    # 1. åˆ›å»ºæ¨¡åž‹ (å…ˆåˆ›å»ºæ¨¡åž‹ï¼Œæ‰èƒ½è¯»å–å®ƒçš„é…ç½®)
    print(f"ðŸ“¦ åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹: {CONFIG['model_name']}...")
    model = timm.create_model(
        CONFIG['model_name'], 
        pretrained=CONFIG['pretrained'], 
        num_classes=CONFIG['num_classes']
    )
    model.to(CONFIG['device'])
    
    # ========================================================
    # ðŸ”¥ å…³é”®ä¿®æ­£: è‡ªåŠ¨ä»Žæ¨¡åž‹è¯»å–æ­£ç¡®çš„é¢„å¤„ç†å‚æ•°
    # ========================================================
    data_config = resolve_data_config(model.default_cfg, model=model)
    print(f"ðŸ”§ è‡ªåŠ¨è¯»å–é¢„å¤„ç†å‚æ•°: {data_config}")
    # é¢„æœŸè¾“å‡ºä¸­åº”åŒ…å«: 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5)

    # 2. ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åˆ›å»º Transform
    # è®­ç»ƒé›†å¢žå¼º (ä¿æŒå¼ºå¢žå¼ºï¼Œä½†ä½¿ç”¨æ­£ç¡®çš„ mean/std)
    train_transform = create_transform(
        input_size=data_config['input_size'],
        is_training=True,
        auto_augment='rand-m9-mstd0.5-inc1', 
        interpolation=data_config['interpolation'],
        mean=data_config['mean'], # ä¿®æ­£ç‚¹
        std=data_config['std']    # ä¿®æ­£ç‚¹
    )
    
    # éªŒè¯é›†é¢„å¤„ç† (å®Œå…¨åŒ¹é…è®­ç»ƒæ—¶çš„è®¾ç½®)
    val_transform = create_transform(
        input_size=data_config['input_size'],
        is_training=False,
        interpolation=data_config['interpolation'],
        mean=data_config['mean'], # ä¿®æ­£ç‚¹
        std=data_config['std'],   # ä¿®æ­£ç‚¹
        crop_pct=data_config['crop_pct'] # ä¿®æ­£ç‚¹: ç¡®ä¿è£å‰ªæ¯”ä¾‹æ­£ç¡®
    )

    # 3. æ•°æ®åŠ è½½ (Loader éƒ¨åˆ†ä¿æŒä¸å˜)
    train_dir = os.path.join(CONFIG['data_dir'], 'train')
    val_dir = os.path.join(CONFIG['data_dir'], 'val')
    
    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)
    val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)
    
    train_loader = DataLoader(
        train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, 
        num_workers=CONFIG['num_workers'], pin_memory=True, persistent_workers=True, drop_last=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, 
        num_workers=CONFIG['num_workers'], pin_memory=True
    )

    # ==========================================
    # 3. éªŒè¯é˜¶æ®µ 1: æ‰‹æœ¯å‰ (Baseline)
    # ==========================================
    acc_baseline = validate_model(model, val_loader, CONFIG['device'], description="[1/2] æ‰‹æœ¯å‰åŸºå‡†éªŒè¯")
    
    # 4. æ‰§è¡Œæ‰‹æœ¯
    # å¿…é¡»é‡æ–°ç§»å›ž CPU åšæ‰‹æœ¯å—ï¼Ÿå…¶å®žä¸éœ€è¦ï¼Œä½†å¦‚æžœæ˜¾å­˜ç´§å¼ å¯ä»¥è€ƒè™‘ã€‚
    # è¿™é‡Œç›´æŽ¥åœ¨å½“å‰è®¾å¤‡æˆ–è‡ªåŠ¨å¤„ç†ï¼Œå› ä¸º replace å‡½æ•°é‡Œæ–°å»ºå±‚é»˜è®¤åœ¨ CPU
    model = replace_linear_with_golay(model, block_size=128)
    
    # æ‰‹æœ¯åŽï¼Œæ–°å±‚åœ¨ CPUï¼Œå¿…é¡»å†æ¬¡ .to(device)
    model.to(CONFIG['device'])

    # ==========================================
    # 5. éªŒè¯é˜¶æ®µ 2: æ‰‹æœ¯åŽ (Check Consistency)
    # ==========================================
    acc_surgery = validate_model(model, val_loader, CONFIG['device'], description="[2/2] æ‰‹æœ¯åŽç­‰ä»·æ€§éªŒè¯")
    
    print("\n" + "="*40)
    print(f"ðŸ©º å¥åº·æ£€æŸ¥æŠ¥å‘Š:")
    print(f"   æ‰‹æœ¯å‰ Acc: {acc_baseline:.2f}%")
    print(f"   æ‰‹æœ¯åŽ Acc: {acc_surgery:.2f}%")
    print(f"   å·®å¼‚: {acc_surgery - acc_baseline:.2f}%")
    if abs(acc_surgery - acc_baseline) < 0.5:
        print("âœ… éªŒè¯é€šè¿‡ï¼šGolayå˜æ¢ä¿æŒäº†æ•°å­¦ç­‰ä»·æ€§ï¼")
    else:
        print("âš ï¸ è­¦å‘Šï¼šç²¾åº¦å·®å¼‚è¾ƒå¤§ï¼Œè¯·æ£€æŸ¥å®žçŽ°é€»è¾‘ï¼")
    print("="*40 + "\n")

    # 6. å¼€å§‹å¾®è°ƒè®­ç»ƒ
    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])
    scheduler = CosineLRScheduler(optimizer, t_initial=CONFIG['epochs'], lr_min=1e-6, warmup_t=3, warmup_lr_init=1e-6)
    criterion = nn.CrossEntropyLoss()
    scaler = GradScaler()

    best_acc = acc_surgery # ä»¥æ‰‹æœ¯åŽçš„ç²¾åº¦ä¸ºèµ·ç‚¹
    
    print("ðŸ”¥ å¼€å§‹å¾®è°ƒè®­ç»ƒ...")
    for epoch in range(CONFIG['epochs']):
        model.train()
        train_loss = 0.0
        total_train = 0
        train_correct = 0
        
        scheduler.step(epoch)
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{CONFIG['epochs']}")
        
        for images, labels in pbar:
            images, labels = images.to(CONFIG['device']), labels.to(CONFIG['device'])
            optimizer.zero_grad()
            with autocast():
                outputs = model(images)
                loss = criterion(outputs, labels)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            train_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total_train += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
            pbar.set_postfix({'loss': f"{loss.item():.4f}", 'lr': f"{optimizer.param_groups[0]['lr']:.1e}"})
            
        avg_train_loss = train_loss / total_train
        
        # Epoch éªŒè¯
        val_acc = validate_model(model, val_loader, CONFIG['device'], description=f"Epoch {epoch+1} Val")
        
        print(f"ðŸ“Š Epoch {epoch+1}: Loss {avg_train_loss:.4f} | Val Acc {val_acc:.2f}%")
        
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), "/content/drive/MyDrive/vit_golay_qkv_fc1_best.pth")
            print(f"   ðŸ’¾ Best Model Saved ({best_acc:.2f}%)")

if __name__ == '__main__':
    main()